#!rnn.py


from returnn.tf.util.data import DimensionTag
import os
import numpy as np
from subprocess import check_output, CalledProcessError


def summary(name, x):
    """
    :param str name:
    :param tf.Tensor x: (batch,time,feature)
    """
    import tensorflow as tf

    # tf.summary.image wants [batch_size, height,  width, channels],
    # we have (batch, time, feature).
    img = tf.expand_dims(x, axis=3)  # (batch,time,feature,1)
    img = tf.transpose(img, [0, 2, 1, 3])  # (batch,feature,time,1)
    tf.summary.image(name, img, max_outputs=10)
    tf.summary.scalar("%s_max_abs" % name, tf.reduce_max(tf.abs(x)))
    mean = tf.reduce_mean(x)
    tf.summary.scalar("%s_mean" % name, mean)
    stddev = tf.sqrt(tf.reduce_mean(tf.square(x - mean)))
    tf.summary.scalar("%s_stddev" % name, stddev)
    tf.summary.histogram("%s_hist" % name, tf.reduce_max(tf.abs(x), axis=2))


def _mask(x, batch_axis, axis, pos, max_amount, mask_value=0.0):
    """
    :param tf.Tensor x: (batch,time,feature)
    :param int batch_axis:
    :param int axis:
    :param tf.Tensor pos: (batch,)
    :param int|tf.Tensor max_amount: inclusive
    :param float|int mask_value:
    """
    import tensorflow as tf

    ndim = x.get_shape().ndims
    n_batch = tf.shape(x)[batch_axis]
    dim = tf.shape(x)[axis]
    amount = tf.random.uniform(
        shape=(n_batch,), minval=1, maxval=max_amount + 1, dtype=tf.int32
    )
    pos2 = tf.minimum(pos + amount, dim)
    idxs = tf.expand_dims(tf.range(0, dim), 0)  # (1,dim)
    pos_bc = tf.expand_dims(pos, 1)  # (batch,1)
    pos2_bc = tf.expand_dims(pos2, 1)  # (batch,1)
    cond = tf.logical_and(
        tf.greater_equal(idxs, pos_bc), tf.less(idxs, pos2_bc)
    )  # (batch,dim)
    if batch_axis > axis:
        cond = tf.transpose(cond)  # (dim,batch)
    cond = tf.reshape(
        cond, [tf.shape(x)[i] if i in (batch_axis, axis) else 1 for i in range(ndim)]
    )
    from returnn.tf.util.basic import where_bc

    x = where_bc(cond, mask_value, x)
    return x


def random_mask(x, batch_axis, axis, min_num, max_num, max_dims, mask_value=0.0):
    """
    :param tf.Tensor x: (batch,time,feature)
    :param int batch_axis:
    :param int axis:
    :param int|tf.Tensor min_num:
    :param int|tf.Tensor max_num: inclusive
    :param int|tf.Tensor max_dims: inclusive
    :param float|int mask_value:
    """
    import tensorflow as tf
    from returnn.tf.util.basic import expand_multiple_dims

    n_batch = tf.shape(x)[batch_axis]
    if isinstance(min_num, int) and isinstance(max_num, int) and min_num == max_num:
        num = min_num
    else:
        num = tf.random.uniform(
            shape=(n_batch,), minval=min_num, maxval=max_num + 1, dtype=tf.int32
        )
    # https://github.com/tensorflow/tensorflow/issues/9260
    # https://timvieira.github.io/blog/post/2014/08/01/gumbel-max-trick-and-weighted-reservoir-sampling/
    z = -tf.math.log(
        -tf.math.log(tf.random.uniform((n_batch, tf.shape(x)[axis]), 0, 1))
    )
    _, indices = tf.nn.top_k(z, num if isinstance(num, int) else tf.reduce_max(num))
    # indices should be sorted, and of shape (batch,num), entries (int32) in [0,dim)
    # indices = tf.Print(indices, ["indices", indices, tf.shape(indices)])
    if isinstance(num, int):
        for i in range(num):
            x = _mask(
                x,
                batch_axis=batch_axis,
                axis=axis,
                pos=indices[:, i],
                max_amount=max_dims,
                mask_value=mask_value,
            )
    else:
        _, x = tf.while_loop(
            cond=lambda i, _: tf.less(i, tf.reduce_max(num)),
            body=lambda i, x: (
                i + 1,
                tf.where(
                    expand_multiple_dims(
                        tf.less(i, num), axes=[-1] * (len(x.shape) - len(num.shape))
                    ),
                    _mask(
                        x,
                        batch_axis=batch_axis,
                        axis=axis,
                        pos=indices[:, i],
                        max_amount=max_dims,
                        mask_value=mask_value,
                    ),
                    x,
                ),
            ),
            loop_vars=(0, x),
        )
    return x


def transform(data, network, time_factor=1):
    x = data.placeholder
    import tensorflow as tf

    # summary("features", x)
    step = network.global_train_step
    step1 = tf.where(tf.greater_equal(step, 1000), 1, 0)
    step2 = tf.where(tf.greater_equal(step, 2000), 1, 0)

    def get_masked():
        x_masked = x
        x_masked = random_mask(
            x_masked,
            batch_axis=data.batch_dim_axis,
            axis=data.time_dim_axis,
            min_num=step1 + step2,
            max_num=tf.maximum(tf.shape(x)[data.time_dim_axis] // 100, 2)
            * (1 + step1 + step2 * 2),
            max_dims=20 // time_factor,
        )
        x_masked = random_mask(
            x_masked,
            batch_axis=data.batch_dim_axis,
            axis=data.feature_dim_axis,
            min_num=step1 + step2,
            max_num=2 + step1 + step2 * 2,
            max_dims=data.dim // 5,
        )
        # summary("features_mask", x_masked)
        return x_masked

    x = network.cond_on_train(get_masked, lambda: x)
    return x


def get_vocab_tf():
    from returnn.datasets.generating import Vocabulary
    from returnn.tf.util.basic import get_shared_vocab

    vocab = Vocabulary.create_vocab(**eval("vocab"))
    labels = vocab.labels  # bpe labels ("@@" at end, or not), excluding blank
    labels = [(l + " ").replace("@@ ", "") for l in labels] + [""]
    labels_t = get_shared_vocab(labels)
    return labels_t


def get_vocab_sym(i):
    """
    :param tf.Tensor i: e.g. [B], int32
    :return: same shape as input, string
    :rtype: tf.Tensor
    """
    import tensorflow as tf

    return tf.gather(params=get_vocab_tf(), indices=i)


def out_str(source, **kwargs):
    # ["prev:out_str", "output_emit", "output"]
    import tensorflow as tf
    from returnn.tf.util.basic import where_bc

    with tf.device("/cpu:0"):
        return source(0) + where_bc(
            source(1), get_vocab_sym(source(2)), tf.constant("")
        )


def targetb_recomb_recog(
    layer, batch_dim, scores_in, scores_base, base_beam_in, end_flags, **kwargs
):
    """
    :param ChoiceLayer layer:
    :param tf.Tensor batch_dim: scalar
    :param tf.Tensor scores_base: (batch,base_beam_in,1). existing beam scores
    :param tf.Tensor scores_in: (batch,base_beam_in,dim). log prob frame distribution
    :param tf.Tensor end_flags: (batch,base_beam_in)
    :param tf.Tensor base_beam_in: int32 scalar, 1 or prev beam size
    :rtype: tf.Tensor
    :return: (batch,base_beam_in,dim), combined scores
    """
    import tensorflow as tf

    prev_str = layer.explicit_search_sources[0].output  # [B*beam], str
    prev_str_t = tf.reshape(prev_str.placeholder, (batch_dim, -1))[:, :base_beam_in]

    # Pre-filter approx (should be much faster), sum approx (better).
    scores_base = tf.reshape(
        get_filtered_score_cpp(
            prev_str_t, tf.reshape(scores_base, (batch_dim, base_beam_in))
        ),
        (batch_dim, base_beam_in, 1),
    )

    scores = scores_in + scores_base  # (batch,beam,dim)

    return scores


def get_filtered_score_op(verbose=False):
    cpp_code = """
  #include "tensorflow/core/framework/op.h"
  #include "tensorflow/core/framework/op_kernel.h"
  #include "tensorflow/core/framework/shape_inference.h"
  #include "tensorflow/core/framework/resource_mgr.h"
  #include "tensorflow/core/framework/resource_op_kernel.h"
  #include "tensorflow/core/framework/tensor.h"
  #include "tensorflow/core/platform/macros.h"
  #include "tensorflow/core/platform/mutex.h"
  #include "tensorflow/core/platform/types.h"
  #include "tensorflow/core/public/version.h"
  #include <cmath>
  #include <map>
  #include <set>
  #include <string>
  #include <tuple>

  using namespace tensorflow;

  REGISTER_OP("GetFilteredScore")
  .Input("prev_str: string")
  .Input("scores: float32")
  //.Input("labels: string")
  .Output("new_scores: float32")
  .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
      c->set_output(0, c->input(1));
      return Status::OK();
  });

  class GetFilteredScoreOp : public OpKernel {
  public:
  using OpKernel::OpKernel;
  void Compute(OpKernelContext* context) override {
      const Tensor* prev_str = &context->input(0);
      const Tensor* scores = &context->input(1);
      //const Tensor* labels = &context->input(2);

      int n_batch = prev_str->shape().dim_size(0);
      int n_beam = prev_str->shape().dim_size(1);

      Tensor* ret;
      OP_REQUIRES_OK(context, context->allocate_output(0, TensorShape({n_batch, n_beam}), &ret));
      for(int bat = 0; bat < n_batch; ++bat)
          for(int hyp = 0; hyp < n_beam; ++hyp)
              ret->tensor<float, 2>()(bat, hyp) = scores->tensor<float, 2>()(bat, hyp);

      for(int bat = 0; bat < n_batch; ++bat) {
          std::map<tstring, std::set<int> > new_hyps;  // seq -> set of hyp idx

          for(int hyp = 0; hyp < n_beam; ++hyp) {
              auto& seq_set = new_hyps[prev_str->tensor<tstring, 2>()(bat, hyp)];
              seq_set.insert(hyp);
          }

          for(const auto& items : new_hyps) {
              if(std::get<1>(items).size() > 1) {
                  float best_score = 0.;
                  int best_idx = -1;
                  for(int idx : std::get<1>(items)) {
                      float score = scores->tensor<float, 2>()(bat, idx);
                      if(score > best_score || best_idx == -1) {
                          best_score = score;
                          best_idx = idx;
                      }
                  }

                  float sum_score = 0.;
                  for(int idx : std::get<1>(items)) {
                      float score = scores->tensor<float, 2>()(bat, idx);
                      sum_score += expf(score - best_score);
                  }
                  sum_score = logf(sum_score) + best_score;

                  for(int idx : std::get<1>(items)) {
                      if(idx != best_idx)
                          ret->tensor<float, 2>()(bat, idx) = -std::numeric_limits<float>::infinity();
                      else
                          ret->tensor<float, 2>()(bat, idx) = sum_score;
                  }
              }
          }
      }
  }
  };
  REGISTER_KERNEL_BUILDER(Name("GetFilteredScore").Device(DEVICE_CPU), GetFilteredScoreOp);
  """
    from returnn.tf.util.basic import OpCodeCompiler

    compiler = OpCodeCompiler(
        base_name="GetFilteredScore",
        code_version=1,
        code=cpp_code,
        is_cpp=True,
        use_cuda_if_available=False,
        verbose=verbose,
    )
    tf_mod = compiler.load_tf_module()
    return tf_mod.get_filtered_score


def get_filtered_score_cpp(prev_str, scores):
    """
    :param tf.Tensor prev_str: (batch,beam)
    :param tf.Tensor scores: (batch,beam)
    :param list[bytes] labels: len (dim)
    :return: scores with logsumexp at best, others -inf, (batch,beam)
    :rtype: tf.Tensor
    """
    import tensorflow as tf

    with tf.device("cpu:0"):
        return get_filtered_score_op()(prev_str, scores)


def cf(filename):
    """Cache manager"""
    import os
    from subprocess import check_output, CalledProcessError

    if filename in eval("_cf_cache"):
        return eval("_cf_cache")[filename]
    if check_output(["hostname"]).strip().decode("utf8") in [
        "cluster-cn-211",
        "sulfid",
    ]:
        print("use local file: %s" % filename)
        return filename  # for debugging
    try:
        cached_fn = check_output(["cf", filename]).strip().decode("utf8")
    except CalledProcessError:
        print("Cache manager: Error occured, using local file")
        return filename
    assert os.path.exists(cached_fn)
    eval("_cf_cache")[filename] = cached_fn
    return cached_fn


def get_dataset_dict(data):
    import os

    assert data in {"train", "devtrain", "cv", "dev", "hub5e_01", "rt03s"}
    epoch_split = {"train": eval("epoch_split")}.get(data, 1)
    corpus_name = {"cv": "train", "devtrain": "train"}.get(
        data, data
    )  # train, dev, hub5e_01, rt03s

    hdf_files = None
    if data in {"train", "cv", "devtrain"} and eval("_alignment"):
        hdf_files = [
            "%s.data-%s.hdf"
            % (eval("_alignment"), {"cv": "dev", "devtrain": "train"}.get(data, data))
        ]

    files = {
        "config": eval("rasr_config"),
        "corpus": "/work/asr3/irie/data/switchboard/corpora/%s.corpus.gz" % corpus_name,
    }
    if data in {"train", "cv", "devtrain"}:
        files["segments"] = (
            "/u/schmitt/experiments/transducer/config/dependencies/seg_%s"
            % {"train": "train", "cv": "cv_head3000", "devtrain": "train_head3000"}[
                data
            ]
        )
    files["features"] = (
        "/u/tuske/work/ASR/switchboard/feature.extraction/gt40_40/data/gt.%s.bundle"
        % corpus_name
    )

    for k, v in sorted(files.items()):
        assert os.path.exists(v), "%s %r does not exist" % (k, v)
    estimated_num_seqs = {
        "train": 227047,
        "cv": 3000,
        "devtrain": 3000,
    }  # wc -l segment-file

    args = [
        "--config=" + files["config"],
        lambda: "--*.corpus.file=" + cf(files["corpus"]),
        lambda: "--*.corpus.segments.file=" + cf(files["segments"])
        if "segments" in files
        else "",
        lambda: "--*.feature-cache-path=" + cf(files["features"]),
        "--*.log-channel.file=sprint-log",
        "--*.window-size=1",
    ]

    if not hdf_files:
        args += [
            "--*.corpus.segment-order-shuffle=true",
            "--*.segment-order-sort-by-time-length=true",
            "--*.segment-order-sort-by-time-length-chunk-size=%i"
            % {"train": epoch_split * 1000}.get(data, -1),
        ]

    d = {
        "class": "ExternSprintDataset",
        "sprintTrainerExecPath": "/u/schmitt/experiments/transducer/config/sprint-executables/nn-trainer",
        "sprintConfigStr": args,
        "suppress_load_seqs_print": True,  # less verbose
        "input_stddev": 3.0,
        "orth_vocab": eval("vocab"),
    }

    partition_epochs_opts = {
        "partition_epoch": epoch_split,
        "estimated_num_seqs": (estimated_num_seqs[data] // epoch_split)
        if data in estimated_num_seqs
        else None,
    }

    if hdf_files:
        align_opts = {
            "class": "HDFDataset",
            "files": hdf_files,
            "use_cache_manager": True,
            "seq_list_filter_file": files["segments"],
        }  # otherwise not right selection
        align_opts.update(
            partition_epochs_opts
        )  # this dataset will control the seq list
        if data == "train":
            align_opts["seq_ordering"] = "laplace:%i" % (
                estimated_num_seqs[data] // 1000
            )
            align_opts[
                "seq_order_seq_lens_file"
            ] = "/u/zeyer/setups/switchboard/dataset/data/seq-lens.train.txt.gz"
        d = {
            "class": "MetaDataset",
            "datasets": {"sprint": d, "align": align_opts},
            "data_map": {
                "data": ("sprint", "data"),  # target: ("sprint", target),
                "alignment": ("align", "data"),  # "align_score": ("align", "scores")
            },
            "seq_order_control_dataset": "align",  # it must support get_all_tags
        }
    else:
        d.update(partition_epochs_opts)

    return d


def switchout_target(source, network, **kwargs):
    import tensorflow as tf
    from returnn.tf.util.basic import where_bc

    time_factor = 6
    data = source(0, as_data=True)
    assert data.is_batch_major  # just not implemented otherwise
    x = data.placeholder

    def get_switched():
        x_ = x
        shape = tf.shape(x)
        n_batch = tf.shape(x)[data.batch_dim_axis]
        n_time = tf.shape(x)[data.time_dim_axis]
        take_rnd_mask = tf.less(
            tf.random.uniform(shape=shape, minval=0.0, maxval=1.0), 0.05
        )
        take_blank_mask = tf.less(
            tf.random.uniform(shape=shape, minval=0.0, maxval=1.0), 0.5
        )
        rnd_label = tf.random.uniform(
            shape=shape, minval=0, maxval=eval("target_num_labels"), dtype=tf.int32
        )
        rnd_label = where_bc(take_blank_mask, eval("targetb_blank_idx"), rnd_label)
        x_ = where_bc(take_rnd_mask, rnd_label, x_)
        x_ = eval("random_mask")(
            x_,
            batch_axis=data.batch_dim_axis,
            axis=data.time_dim_axis,
            min_num=0,
            max_num=tf.maximum(
                tf.shape(x)[data.time_dim_axis] // (50 // time_factor), 1
            ),
            max_dims=20 // time_factor,
            mask_value=eval("targetb_blank_idx"),
        )
        # x_ = tf.Print(x_, ["switch", x[0], "to", x_[0]], summarize=100)
        return x_

    x = network.cond_on_train(get_switched, lambda: x)
    return x


def custom_construction_algo(idx, net_dict):
    net_dict["#config"] = {}
    if idx is not None:
        # learning rate warm up
        lr_warmup = list(np.linspace(learning_rate * 0.1, learning_rate, num=10))
        if idx < len(lr_warmup):
            net_dict["#config"]["learning_rate"] = lr_warmup[idx]

    # encoder construction
    start_num_lstm_layers = 2
    final_num_lstm_layers = 6
    num_lstm_layers = final_num_lstm_layers
    if idx is not None:
        idx = max(idx, 0) // 6  # each index is used 6 times
        num_lstm_layers = (
            idx + start_num_lstm_layers
        )  # 2, 3, 4, 5, 6 (each for 6 epochs)
        idx = num_lstm_layers - final_num_lstm_layers
        num_lstm_layers = min(num_lstm_layers, final_num_lstm_layers)

    if final_num_lstm_layers > start_num_lstm_layers:
        start_dim_factor = 0.5
        # grow_frac values: 0, 1/4, 1/2, 3/4, 1
        grow_frac = 1.0 - float(final_num_lstm_layers - num_lstm_layers) / (
            final_num_lstm_layers - start_num_lstm_layers
        )
        # dim_frac values: 0.5, 5/8, 3/4, 7/8, 1
        dim_frac = start_dim_factor + (1.0 - start_dim_factor) * grow_frac
    else:
        dim_frac = 1.0
    net_dict["#info"].update(
        {"dim_frac": dim_frac, "num_lstm_layers": num_lstm_layers, "pretrain_idx": idx}
    )

    time_reduction = [3, 2] if num_lstm_layers >= 3 else [6]

    # Add encoder BLSTM stack
    src = "conv_merged"
    lstm_dim = net_dict["#info"]["lstm_dim"]
    l2 = net_dict["#info"]["l2"]
    if num_lstm_layers >= 1:
        net_dict.update(
            {
                "lstm0_fw": {
                    "class": "rec",
                    "unit": "nativelstm2",
                    "n_out": int(lstm_dim * dim_frac),
                    "L2": l2,
                    "direction": 1,
                    "from": src,
                    "trainable": True,
                },
                "lstm0_bw": {
                    "class": "rec",
                    "unit": "nativelstm2",
                    "n_out": int(lstm_dim * dim_frac),
                    "L2": l2,
                    "direction": -1,
                    "from": src,
                    "trainable": True,
                },
            }
        )
        src = ["lstm0_fw", "lstm0_bw"]
    for i in range(1, num_lstm_layers):
        red = time_reduction[i - 1] if (i - 1) < len(time_reduction) else 1
        net_dict.update(
            {
                "lstm%i_pool"
                % (i - 1): {
                    "class": "pool",
                    "mode": "max",
                    "padding": "same",
                    "pool_size": (red,),
                    "from": src,
                }
            }
        )
        src = "lstm%i_pool" % (i - 1)
        net_dict.update(
            {
                "lstm%i_fw"
                % i: {
                    "class": "rec",
                    "unit": "nativelstm2",
                    "n_out": int(lstm_dim * dim_frac),
                    "L2": l2,
                    "direction": 1,
                    "from": src,
                    "dropout": 0.3 * dim_frac,
                    "trainable": True,
                },
                "lstm%i_bw"
                % i: {
                    "class": "rec",
                    "unit": "nativelstm2",
                    "n_out": int(lstm_dim * dim_frac),
                    "L2": l2,
                    "direction": -1,
                    "from": src,
                    "dropout": 0.3 * dim_frac,
                    "trainable": True,
                },
            }
        )
        src = ["lstm%i_fw" % i, "lstm%i_bw" % i]
    net_dict["encoder0"] = {"class": "copy", "from": src}  # dim: EncValueTotalDim

    # if necessary, include dim_frac in the attention values
    # TODO check if this is working
    try:
        if net_dict["output"]["unit"]["att_val"]["class"] == "linear":
            net_dict["output"]["unit"]["att_val"]["n_out"] = 2 * int(
                lstm_dim * dim_frac
            )
    except KeyError:
        pass

    # We use this pretrain construction during the whole training time
    if idx is not None and idx % epoch_split == 0 and idx > num_epochs:
        # Stop pretraining now.
        return None

    return net_dict


_alignment = "/work/asr3/zeyer/schmitt/sisyphus_work_dirs/merboldt_swb_transducer/rna-tf2.blank0.enc6l-grow2l.scratch-lm.rdrop02.lm1-1024.attwb5-drop02.l2_1e_4.mlr50.epoch-150.swap"
_cf_cache = {}
accum_grad_multiple_step = 2
adam = True
batch_size = 10000
batching = "random"
beam_size = 4
chunking = ({"alignment": 60, "data": 360}, {"alignment": 30, "data": 180})
cleanup_old_models = {"keep": [150]}
debug_print_layer_output_template = True
device = "gpu"
epoch_split = 6
extern_data = {"alignment": {"dim": 1031, "sparse": True}, "data": {"dim": 40}}
gradient_clip = 0
gradient_noise = 0.0
learning_rate = 0.001
learning_rate_control = "newbob_multi_epoch"
learning_rate_control_error_measure = "dev_error_output/output_prob"
learning_rate_control_min_num_epochs_per_new_lr = 3
learning_rate_control_relative_error_relative_lr = True
log = ["./returnn.log"]
log_batch_size = True
log_verbosity = 5
max_seqs = 200
min_learning_rate = 2e-05

# set before network because network construction depends on the task
ext_task = config.value("ext_task", None)
task = ext_task

max_seq_length = {"orth_classes": 75} if task == "train" else 0

network = {
    "#info": {"l2": 0.0001, "lstm_dim": 1024},
    "1_targetb_base": {
        "class": "copy",
        "from": "existing_alignment",
        "register_as_extern_data": "targetb_base" if task == "train" else None,
    },
    "2_targetb_target": {
        "class": "eval",
        "eval": "source(0)",
        "from": "data:targetb_base",
        "register_as_extern_data": "targetb" if task == "train" else None,
    },
    "3_target_masked": {
        "class": "reinterpret_data",
        "enforce_batch_major": True,
        "from": "_target_masked",
        "register_as_extern_data": "targetb_masked" if task == "train" else None,
        "set_sparse_dim": 1030,
    },
    "_target_masked": {
        "class": "masked_computation",
        "from": "output",
        "mask": "output/output_emit",
        "unit": {"class": "copy"},
    },
    "conv0": {
        "activation": None,
        "auto_use_channel_first": False,
        "class": "conv",
        "filter_size": (3, 3),
        "from": "source0",
        "n_out": 32,
        "padding": "same",
        "with_bias": True,
    },
    "conv0p": {
        "class": "pool",
        "from": "conv0",
        "mode": "max",
        "padding": "same",
        "pool_size": (1, 2),
        "use_channel_first": False,
    },
    "conv1": {
        "activation": None,
        "auto_use_channel_first": False,
        "class": "conv",
        "filter_size": (3, 3),
        "from": "conv0p",
        "n_out": 32,
        "padding": "same",
        "with_bias": True,
    },
    "conv1p": {
        "class": "pool",
        "from": "conv1",
        "mode": "max",
        "padding": "same",
        "pool_size": (1, 2),
        "use_channel_first": False,
    },
    "conv_merged": {"axes": "static", "class": "merge_dims", "from": "conv1p"},
    "ctc": {
        "class": "copy",
        "from": "ctc_out_scores",
        "loss": "ctc" if task == "train" else None,
        "loss_opts": {
            "beam_width": 1,
            "ctc_opts": {"logits_normalize": False},
            "output_in_log_space": True,
            "use_native": True,
        } if task == "train" else None,
        "target": "targetb_masked" if task == "train" else None,
    },
    "ctc_out": {
        "class": "softmax",
        "from": "encoder",
        "n_out": 1031,
        "with_bias": False,
    },
    "ctc_out_scores": {
        "class": "eval",
        "eval": "safe_log(source(0))",
        "from": ["ctc_out"],
    },
    "decision": {
        "class": "decide",
        "from": "output_wo_b",
        "loss": "edit_distance",
        "only_on_search": True,
        "target": "orth_classes",
    },
    "enc_seq_len": {"class": "length", "from": "encoder", "sparse": True},
    "encoder": {"class": "copy", "from": "encoder0"},
    "encoder0": {"class": "copy", "from": ["lstm5_fw", "lstm5_bw"]},
    "existing_alignment": {
        "class": "reinterpret_data",
        "from": "data:alignment",
        "set_sparse": True,
        "set_sparse_dim": 1031,
        "size_base": "encoder",
    },
    "lstm0_bw": {
        "L2": 0.0001,
        "class": "rec",
        "direction": -1,
        "from": "conv_merged",
        "n_out": 1024,
        "trainable": True,
        "unit": "nativelstm2",
    },
    "lstm0_fw": {
        "L2": 0.0001,
        "class": "rec",
        "direction": 1,
        "from": "conv_merged",
        "n_out": 1024,
        "trainable": True,
        "unit": "nativelstm2",
    },
    "lstm0_pool": {
        "class": "pool",
        "from": ["lstm0_fw", "lstm0_bw"],
        "mode": "max",
        "padding": "same",
        "pool_size": (3,),
    },
    "lstm1_bw": {
        "L2": 0.0001,
        "class": "rec",
        "direction": -1,
        "dropout": 0.3,
        "from": "lstm0_pool",
        "n_out": 1024,
        "trainable": True,
        "unit": "nativelstm2",
    },
    "lstm1_fw": {
        "L2": 0.0001,
        "class": "rec",
        "direction": 1,
        "dropout": 0.3,
        "from": "lstm0_pool",
        "n_out": 1024,
        "trainable": True,
        "unit": "nativelstm2",
    },
    "lstm1_pool": {
        "class": "pool",
        "from": ["lstm1_fw", "lstm1_bw"],
        "mode": "max",
        "padding": "same",
        "pool_size": (2,),
    },
    "lstm2_bw": {
        "L2": 0.0001,
        "class": "rec",
        "direction": -1,
        "dropout": 0.3,
        "from": "lstm1_pool",
        "n_out": 1024,
        "trainable": True,
        "unit": "nativelstm2",
    },
    "lstm2_fw": {
        "L2": 0.0001,
        "class": "rec",
        "direction": 1,
        "dropout": 0.3,
        "from": "lstm1_pool",
        "n_out": 1024,
        "trainable": True,
        "unit": "nativelstm2",
    },
    "lstm2_pool": {
        "class": "pool",
        "from": ["lstm2_fw", "lstm2_bw"],
        "mode": "max",
        "padding": "same",
        "pool_size": (1,),
    },
    "lstm3_bw": {
        "L2": 0.0001,
        "class": "rec",
        "direction": -1,
        "dropout": 0.3,
        "from": "lstm2_pool",
        "n_out": 1024,
        "trainable": True,
        "unit": "nativelstm2",
    },
    "lstm3_fw": {
        "L2": 0.0001,
        "class": "rec",
        "direction": 1,
        "dropout": 0.3,
        "from": "lstm2_pool",
        "n_out": 1024,
        "trainable": True,
        "unit": "nativelstm2",
    },
    "lstm3_pool": {
        "class": "pool",
        "from": ["lstm3_fw", "lstm3_bw"],
        "mode": "max",
        "padding": "same",
        "pool_size": (1,),
    },
    "lstm4_bw": {
        "L2": 0.0001,
        "class": "rec",
        "direction": -1,
        "dropout": 0.3,
        "from": "lstm3_pool",
        "n_out": 1024,
        "trainable": True,
        "unit": "nativelstm2",
    },
    "lstm4_fw": {
        "L2": 0.0001,
        "class": "rec",
        "direction": 1,
        "dropout": 0.3,
        "from": "lstm3_pool",
        "n_out": 1024,
        "trainable": True,
        "unit": "nativelstm2",
    },
    "lstm4_pool": {
        "class": "pool",
        "from": ["lstm4_fw", "lstm4_bw"],
        "mode": "max",
        "padding": "same",
        "pool_size": (1,),
    },
    "lstm5_bw": {
        "L2": 0.0001,
        "class": "rec",
        "direction": -1,
        "dropout": 0.3,
        "from": "lstm4_pool",
        "n_out": 1024,
        "trainable": True,
        "unit": "nativelstm2",
    },
    "lstm5_fw": {
        "L2": 0.0001,
        "class": "rec",
        "direction": 1,
        "dropout": 0.3,
        "from": "lstm4_pool",
        "n_out": 1024,
        "trainable": True,
        "unit": "nativelstm2",
    },
    "output": {
        "back_prop": True,
        "class": "rec",
        "from": "encoder",
        "include_eos": True,
        "max_seq_len": "max_len_from('base:encoder') * 2",
        "size_target": "targetb" if task == "train" else None,
        "target": "targetb",
        "unit": {
            "am": {"class": "copy", "from": "data:source"},
            "att": {"axes": "except_time", "class": "merge_dims", "from": "att0"},
            "att0": {
                "add_var2_if_empty": False,
                "class": "dot",
                "from": ["att_val_split", "att_weights"],
                "reduce": "stag:att_t",
                "var1": "f",
                "var2": None,
            },
            "att_ctx": {
                "L2": 0.0001,
                "activation": None,
                "class": "linear",
                "dropout": 0.2,
                "from": "segments",
                "n_out": 1024,
                "with_bias": False,
            },
            "att_energy": {
                "class": "reinterpret_data",
                "from": "att_energy0",
                "is_output_layer": False,
                "set_dim_tags": {
                    "f": DimensionTag(
                        kind=DimensionTag.Types.Spatial,
                        description="att_heads",
                        dimension=1,
                    )
                },
            },
            "att_energy0": {
                "activation": None,
                "class": "linear",
                "from": ["energy_tanh"],
                "n_out": 1,
                "with_bias": False,
            },
            "att_energy_in": {
                "class": "combine",
                "from": ["att_ctx", "att_query"],
                "kind": "add",
                "n_out": 1024,
            },
            "att_masked": {
                "class": "masked_computation",
                "from": "prev:att",
                "mask": "prev:output_is_not_blank",
                "unit": {"class": "copy", "from": "data"},
            },
            "att_query": {
                "activation": None,
                "class": "linear",
                "from": ["lm"],
                "is_output_layer": True,
                "n_out": 1024,
                "with_bias": False,
            },
            "att_unmasked": {
                "class": "unmask",
                "from": "att_masked",
                "mask": "prev:output_is_not_blank",
            },
            "att_val": {"class": "copy", "from": "segments"},
            "att_val_split": {
                "class": "reinterpret_data",
                "from": "att_val_split0",
                "set_dim_tags": {
                    "dim:1": DimensionTag(
                        kind=DimensionTag.Types.Spatial,
                        description="att_heads",
                        dimension=1,
                    )
                },
            },
            "att_val_split0": {
                "axis": "f",
                "class": "split_dims",
                "dims": (1, -1),
                "from": "att_val",
            },
            "att_weights": {
                "class": "dropout",
                "dropout": 0.1,
                "dropout_noise_shape": {"*": None},
                "from": "att_weights0",
                "is_output_layer": False,
            },
            "att_weights0": {
                "axis": "stag:att_t",
                "class": "softmax_over_spatial",
                "energy_factor": 0.03125,
                "from": "att_energy",
            },
            "blank_log_prob": {
                "class": "eval",
                "eval": "tf.math.log_sigmoid(-source(0))",
                "from": "emit_prob0",
            },
            "const0": {"class": "constant", "collocate_with": "du", "value": 0},
            "const0.0": {"axis": "F", "class": "expand_dims", "from": "const0.0_0"},
            "const0.0_0": {"class": "constant", "value": 0.0, "with_batch_dim": True},
            "const1": {"class": "constant", "value": 1},
            "const1.0": {"axis": "F", "class": "expand_dims", "from": "const1.0_0"},
            "const1.0_0": {"class": "constant", "value": 1.0, "with_batch_dim": True},
            "du": {
                "class": "switch",
                "condition": "output_emit",
                "false_from": "const0",
                "true_from": "const1",
            },
            "emit_log_prob": {
                "activation": "log_sigmoid",
                "class": "activation",
                "from": "emit_prob0",
            },
            "emit_prob0": {
                "activation": None,
                "class": "linear",
                "from": ["s"],
                "is_output_layer": True,
                "n_out": 1,
            },
            "energy_tanh": {
                "activation": "tanh",
                "class": "activation",
                "from": ["att_energy_in"],
            },
            "label_emit_log_prob": {
                "class": "combine",
                "from": ["label_log_prob", "emit_log_prob"],
                "kind": "add",
            },
            "label_log_prob": {
                "activation": "log_softmax",
                "class": "linear",
                "dropout": 0.3,
                "from": "readout",
                "n_out": 1030,
            },
            "label_prob": {
                "activation": "exp",
                "class": "activation",
                "from": "label_log_prob",
            },
            "lm": {"class": "copy", "from": "lm_embed_unmask"},
            "lm_embed_masked": {"class": "copy", "from": "lm_masked"},
            "lm_embed_unmask": {
                "class": "unmask",
                "from": "lm_embed_masked",
                "mask": "prev:output_emit",
            },
            "lm_masked": {
                "class": "masked_computation",
                "from": "prev_out_non_blank",
                "mask": "prev:output_emit",
                "unit": {
                    "class": "subnetwork",
                    "from": "data",
                    "subnetwork": {
                        "input_embed": {
                            "activation": None,
                            "class": "linear",
                            "from": "data",
                            "is_output_layer": True,
                            "n_out": 621,
                            "with_bias": False,
                        },
                        "lstm0": {
                            "class": "rec",
                            "from": ["input_embed"],
                            "n_out": 1024,
                            "unit": "nativelstm2",
                        },
                        "output": {"class": "copy", "from": "lstm0"},
                    },
                },
            },
            "non_blank_embed": {
                "activation": None,
                "class": "linear",
                "from": "prev_out_non_blank",
                "n_out": 621,
                "with_bias": False,
            },
            "out_str": {
                "class": "eval",
                "eval": "self.network.get_config().typed_value('out_str')(source, network=self.network)",
                "from": ["prev:out_str", "output_emit", "output"],
                "initial_output": None,
                "out_type": {"dtype": "string", "shape": ()},
            },
            "output": {
                "beam_size": 4 if task == "train" else 12,
                "cheating": "exclusive" if task == "train" else None,
                "class": "choice",
                "custom_score_combine": targetb_recomb_recog if task == "search" else None,
                "explicit_search_sources": ["prev:out_str", "prev:output"] if task == "search" else None,
                "from": "output_log_prob",
                "initial_output": 0,
                "input_type": "log_prob",
                "target": "targetb",
            },

            "output_": {
              "class": "copy", "from": "output", "initial_output": 0
            },
            "output_emit": {
                "class": "copy",
                "from": "output_is_not_blank",
                "initial_output": True,
                "is_output_layer": True,
            },
            "output_is_not_blank": {
                "class": "compare",
                "from": "output_",
                "initial_output": True,
                "kind": "not_equal",
                "value": 1030,
            },
            "output_log_prob": {
                "class": "copy",
                "from": ["label_emit_log_prob", "blank_log_prob"],
            },
            "output_prob": {
                "activation": "exp",
                "class": "activation",
                "from": "output_log_prob",
                "loss": "ce",
                "loss_opts": {
                    "focal_loss_factor": 2.0,
                    "label_smoothing": None,
                    "scale": 1.0,
                },
                "target": "targetb",
            },
            "prev_non_blank_embed": {
                "class": "unmask",
                "from": "prev_non_blank_embed_masked",
                "mask": "prev:output_emit",
            },
            "prev_non_blank_embed_masked": {
                "class": "masked_computation",
                "from": "prev_out_non_blank",
                "mask": "prev:output_emit",
                "unit": {
                    "activation": None,
                    "class": "linear",
                    "from": "data",
                    "n_out": 128,
                    "with_bias": False,
                },
            },
            "prev_out_embed": {
                "activation": None,
                "class": "linear",
                "from": "prev:output_",
                "n_out": 128,
            },
            "prev_out_non_blank": {
                "class": "reinterpret_data",
                "from": "prev:output_",
                "set_sparse": True,
                "set_sparse_dim": 1030,
            },
            "readout": {
                "class": "reduce_out",
                "from": "readout_in",
                "mode": "max",
                "num_pieces": 2,
            },
            "readout_in": {
                "activation": None,
                "class": "linear",
                "from": ["lm", "att"],
                "n_out": 1000,
            },
            "s": {
                "L2": 0.0001,
                "class": "rec",
                "dropout": 0.3,
                "from": ["am", "prev_out_embed"],
                "n_out": 128,
                "unit": "nativelstm2",
                "unit_opts": {"rec_weight_dropout": 0.3},
            },
            "clamp_size": {  # this is the size to which the segments are clamped
              "class": "constant",
              "value": 6
            },
            "segment_starts0": {  # this is the actual segment start
                "class": "switch",
                "condition": "prev:output_is_not_blank",
                "false_from": "prev:segment_starts0",
                "initial_output": 0,
                "true_from": ":i",
            },
            "segment_lens0_copy": {  # this is the actual segment size -1
                "class": "combine",
                "from": [":i", "segment_starts0"],
                "kind": "sub",
            },
            "segment_lens1_copy": {  # this is the actual segment size
                "class": "combine",
                "from": ["segment_lens0_copy", "const1"],
                "kind": "add",
            },
            "clamp_mask": {  # this mask is true iff a segment len is greater than the clamping size
              "class": "compare",
              "from": ["segment_lens1_copy", "clamp_size"],
              "kind": "greater"
            },
            "clamped_diff": {  # this is the difference between segment lens and the clamp size
              "class": "combine",
              "from": ["segment_lens1_copy", "clamp_size"],
              "kind": "sub"
            },
            "clamped_start": {  # for segments which are greater than the clamping size, this is the new segment start
              "class": "combine",
              "from": ["segment_starts0", "clamped_diff"],
              "kind": "add"
            },
            "segment_starts": {  # if a segment is larger than the clamp size, use the clamped start. otherwise use the normal start
              "class": "switch",
              "condition": "clamp_mask",
              "true_from": "clamped_start",
              "false_from": "segment_starts0"
            },
            "segment_lens0": {
              "class": "combine",
              "kind": "sub",
              "from": [":i", "segment_starts"]
            },
            "segment_lens": {
              "class": "combine",
              "kind": "add",
              "from": ["segment_lens0", "const1"]
            },
            "segments": {
                "class": "reinterpret_data",
                "from": "segments0",
                "set_dim_tags": {
                    "stag:sliced-time:segments": DimensionTag(
                        kind=DimensionTag.Types.Spatial, description="att_t"
                    )
                },
            },
            "segments0": {
                "class": "slice_nd",
                "from": "base:encoder",
                "size": "segment_lens",
                "start": "segment_starts",
            },
            "u": {
                "class": "combine",
                "from": ["prev:u", "du"],
                "initial_output": 0,
                "kind": "add",
            },
        },
    },
    "output_wo_b": {
        "class": "reinterpret_data",
        "from": "output_wo_b0",
        "set_sparse_dim": 1030,
    },
    "output_wo_b0": {
        "class": "masked_computation",
        "from": "output",
        "mask": "output/output_emit",
        "unit": {"class": "copy"},
    },
    "source": {
        "class": "eval",
        "eval": "self.network.get_config().typed_value('transform')(source(0, as_data=True), network=self.network)",
    },
    "source0": {"axis": "F", "class": "split_dims", "dims": (-1, 1), "from": "source"},
}
newbob_learning_rate_decay = 0.7
newbob_multi_num_epochs = 6
newbob_multi_update_interval = 1
num_epochs = 150
optimizer_epsilon = 1e-08
rasr_config = "/u/schmitt/experiments/transducer/config/rasr-configs/merged.config"
save_interval = 1
search_output_layer = "decision"
stop_on_nonfinite_train_score = False
target = "orth_classes"
target_num_labels = 1030
targetb_blank_idx = 1030
targetb_num_labels = 1031
tf_log_memory_usage = True
truncation = -1
cleanup_old_models = {"keep_last_n": 1, "keep_best_n": 1, "keep": [33, 150]}
use_learning_rate_control_always = True
use_tensorflow = True
vocab = {
    "bpe_file": "/work/asr3/irie/data/switchboard/subword_clean/ready/swbd_clean.bpe_code_1k",
    "vocab_file": "/work/asr3/irie/data/switchboard/subword_clean/ready/vocab.swbd_clean.bpe_code_1k",
}

extern_data["data"]["same_dim_tags_as"] = {
    "t": DimensionTag(kind=DimensionTag.Types.Spatial, description="time")
}
extern_data["alignment"]["same_dim_tags_as"] = {
    "t": DimensionTag(kind=DimensionTag.Types.Spatial, description="output-len")
}

if task != "train":
    # During train, we add this via the network (from prev alignment, or linear seg). Otherwise it's not available.
    extern_data["targetb"] = {"dim": targetb_num_labels, "sparse": True, "available_for_inference": False}
    extern_data[target] = {"dim": target_num_labels, "sparse": True}  # must not be used for chunked training

train = get_dataset_dict("train")
dev = get_dataset_dict("cv")
eval_datasets = {"devtrain": get_dataset_dict("devtrain")}
search_data = get_dataset_dict("dev") if task == "search" else None
pretrain = {"copy_param_mode": "subset", "construction_algo": custom_construction_algo}

ext_model = config.value("ext_model", None)
model = ext_model

ext_learning_rate_file = config.value("ext_learning_rate_file", None)
learning_rate_file = ext_learning_rate_file

ext_load = config.value("ext_load", None)
load = ext_load